\chapter{Systematic Uncertainties in the Short Baseline Neutrino Program}

In the previous chapter, the motivation for the Fermilab Short Baseline Neutrino program was presented and the expected event rates were shown, as well as the methods of calculating an expected signal from a 3+1 model.  However, the most detailed simulation (or data analysis, for that matter) is not consequential without a robust calculation of systematic uncertainties.

In this chapter, the systematic uncertainties for the Short Baseline are discussed.  Of particular importance are the uncertainties from the flux and neutrino interactions.  The flux for the Booster Neutrino Beam, while among the best known neutrino beam fluxes, still has residual uncertainties of up to 15\% \cite{AguilarArevalo:2008yp}.  Similarly, the uncertainty in the model of neutrino interactions has a 10 to 15\% normalization uncertainty for the quasi-elastic and resonant events that are most important to the oscillation searches.  Considering that the amplitude of any sterile neutrino oscillation effect is very small, with oscillation probabilities that peak at 1\% or less, constraining the systematic uncertainties in the Short Baseline Program is absolutely essential.

The strength of the Short Baseline Program's oscillation search comes, ultimately, from two factors:  the \lartpc technology allows excellent event identification and background rejections, and the near detector, SBND, allows for large cancellation of systematic uncertainties.  In this chapter, the method for quantifying the cancellation of systematic uncertainties is presented.


\section{General Framework for quantification of uncertainties}

\label{sec:multi_weight}

In this analysis, the uncertainties that matter are the systematic uncertainties on the final distribution of event rates.  Since the goal is to produce a sensitivity calculation for an expected signal, the numerical value of the sensitivity can be calculated with a $\chi^2$ calculation:

\begin{equation}
\begin{centering}
\label{eq:chi_sq}
\chi^2(\Delta m^2, \text{sin}^2 2 \theta ) = \sum_{i,j} [N^{null}_i - N^{osc}_i(\Delta m^2, \text{sin}^2 2 \theta ) ] \times E^{-1}_{i,j} \times [N^{null}_j - N^{osc}_j(\Delta m^2, \text{sin}^2 2 \theta ) ],
\end{centering}
\end{equation}

where $N^{null}_i$ is the expected event rate in the $i^{th}$ analysis bin with no oscillation signal, and $N^{osc}_i(\Delta m^2, \text{sin}^2 2 \theta )$ is the expected event rate in the $i^{th}$ analysis bin if there is an oscillation signal from a 3+1 model with the specified mass splitting and amplitude.  In the \nue appearance analysis, this is simplified to 
\begin{equation}
\begin{centering}
N^{null}_i - N^{osc}_i(\Delta m^2, \text{sin}^2 2 \theta ) = S_i(\Delta m^2, \text{sin}^2 2 \theta )
\end{centering}
\end{equation}
where S is the expected signal events from the specified parameters in the $i^{th}$ bin.

$E_{i,j}$ in the $\chi^2$ computation is the covariance matrix, a statistical tool to encode correlated uncertainties.  In practice, the computation of the covariance matrix is the most challenging aspect of the $\chi^2$ calculation because it requires careful determination of how the uncertainties under study are correlated.  For this work, the correlations of uncertainties are quantified with the ``multiple universe'' method \footnote{Nothing to do with the cosmological idea of the multiverse}.  Much more will be said about the computation and use of the covariance matrix in Section~\ref{sec:covariance_matrix}.

\subsection{Multiple Universe Error Propagation and Reweighing methods}

In a complex chain of simulation and analysis such as a prediction of event rates in a neutrino detector, it can be challenging to understand the effect of, for example, an uncertainty of hadron production at the proton target on the final distribution of neutrino events in the detector.  Some intuitive knowledge is of course present: if the amount of neutrino producing particles generated at the target by proton interactions is under (or over) estimated, the event rates in the final analysis distribution at the detector will also be under (over) estimated.  To precisely quantify the relationship between initial variable underlying the simulation and the final distributions of events, a reweighing scheme with multiple universes is used.

\subsubsection{Reweighing Events}

The the models used in the Monte Carlo simulations of neutrino experiments, there is always a class of parameters that feed the models and simulations:  the neutrino cross sections dictate how many events appear in the detector; the hadron interaction cross section dictates both the amount and variation of hadrons produced in the beam target.  These broad examples are meant to highlight that the Monte Carlo must be based upon not just a physics model but the input parameters to that model.  In the case of hadron production when the protons interact with the target, an assumption must be made about the cross section of that interaction.  While the Monte Carlo is naturally based on the best estimate of the input parameters, it's insufficient to estimate the uncertainty in the simulation without using the uncertainty on the input parameters.

As a concrete example, the beam simulation (originally developed by the \MB collaboration) for the Booster Neutrino Beam uses the Sangford-Wang parameterization to model the double differential pion production cross section for secondary particles at the target.  The parameterization, 

\begin{equation}
\begin{centering}
\frac{d^2 \sigma}{dp d\Omega}(p,\theta) = c_1 \left(1 - \frac{p}{p_B - c_9}\right)\text{exp}\left(- c_3 \frac{p^{c_4}}{p^{c_5}_B} - c_6 \theta (p - c_7 p_B \text{cos}^{c_8}\theta) \right),
\end{centering}
\end{equation}

is a complicated system with eight free parameters which have been fit against data from the HARP and BNL E901 experiments.  The parameters are also not independent, but instead can have strong correlations.  The knowledge of these parameters is not perfect, and indeed the best fit parameters have imperfect agreement with data (see Figure~\ref{fig:sanford_wang_harp}).  However, the fact that the parameters are correlated allows some freedom to change the fit parameters such that the overall parameterization remains consistent with data.  When the parameters are changed from the nominal value to a different, consistent parameterization, it is a different ``Universe'' for this set of parameters.  It's worth noting that the variation in the cross section that comes about by varying the paremeters is the source of the dashed bands in Figure~\ref{fig:sanford_wang_harp}.

In general, varying underlying physical parameters to a model produces a new result.  Unfortunately, Monte Carlo simulation of neutrino beams and interactions is computationally expensive, and repeating the simulation for every variance of a parameter is not possible.  In this case, a `reweighting scheme' is used.  For the moment, assume in a particular universe the Sanford-Wang parameterization above has been increased by a factor $X$ for a particular neutrino in the simulation.  Rather than reproduce this neutrino, in the computation of the final event distributions the same event is used in the same energy bin, but is given a relative weight of $1 + X$.  This factor can be recomputed for every neutrino that is in the final distribution, leading to an event rate distribution that would have been found if the entire simulation were repeated.

In general, this method of `reweighting' applies new weights to every neutrino in the final analysis for each ``Universe.''  By varying the underlying parameters (in a way that leaves them consistent with constraining data) of a physical model many times, a large sample of universes is obtained, and the event distributions can be computed in each universe.  The parameters, however, can not be tweaked completely at random and instead must be drawn according to a Gaussian distribution (if a single uncertainty) or through more complicated methods if a series of correlated parameters.  \MB, for example, varies the Sanford-Wang parameters together through the Cholesky method.


\begin{figure}[tb]
  \centering
  \includegraphics[width=\textwidth]{systematics_figures/sanford_wang_harp}
  \caption[HARP Data and Sanford-Wang Fit]{The HARP Data (points), and the Sanford-Wang best fit parameterization (solid line).  The dashed lines represent a 68\% uncertainty band on the parameterization model from varying the fit parameters within their correlated uncertainties.  The Figure from \cite{AguilarArevalo:2008yp}.}
  \label{fig:sanford_wang_harp}
\end{figure}

\section{Determination of Covariance Matrices}
\label{sec:covariance_matrix}

Using the methods described above for applying weights on an event-by-event basis, it's possible to generate a suite of ``Universes'' of event rate histograms, where the value of each analysis bin can be known in each universe as $N^i_{\text{Univ.} m}.$  In this document, since there are three detectors under consideration, the vector of event rates in each analysis bin, $N$, is a concatenation of the vector of event rates in each detector.  If there are $P$ total analysis bins in each detector, then 
\begin{equation}
\begin{centering}
\vec{N}_{\text{Nom.}} = \left(~N_{\text{Nom.}}^{1,~SBND},~\dots~N_{\text{Nom.}}^{P,~SBND},~N_{\text{Nom.}}^{1,~\uboone}~\dots~N_{\text{Nom.}}^{P,~\uboone},~N_{\text{Nom.}}^{1,~\icarus}~\dots~N_{\text{Nom.}}^{P,~\icarus} ~\right)
\end{centering}
\end{equation}
and in each universe where an underlying physical parameter has been varied:
\begin{equation}
\begin{centering}
\vec{N}_{\text{Univ.}~m} = \left(~N_{\text{Univ.}~m}^{1,~SBND},~\dots~N_{\text{Univ.}~m}^{P,~SBND},~N_{\text{Univ.}~m}^{1,~\uboone}~\dots~N_{\text{Univ.}~m}^{P,~\uboone},~N_{\text{Univ.}~m}^{1,~\icarus}~\dots~N_{\text{Univ.}~m}^{P,~\icarus} ~\right).
\end{centering}
\end{equation}

With these vectors, it's possible to calculate deviation from the nominal values due to the underlying uncertainties in an analysis bin:
\begin{equation}
\begin{centering}
\sigma^i = \sqrt{\frac{1}{M}\sum_{\text{All Univ.}~m}^{M} \left( N^i_{\text{Nom.}} - N^i_{\text{Univ.~m}}\right)^2}
\end{centering}
\label{eq:bin_uncert}
\end{equation}

This measurement of the uncertainty in this way gives an estimate of the uncertainty in single detector experiments, where bin to bin correlations are ignored.  In other words, $\sigma^i$ is the uncertainty in the $i^{th}$ analysis bin when the existence of all the other bins, in any detector, are ignored.  See Figures~\ref{fig:sys_flux_uncert_fracUncert}, \ref{fig:sys_xsec_uncert_fracUncert} for this measurement due to flux and cross section uncertainties, below.  In a practical sense, this measurement of the uncertainty is not useful for the computation of sensitivities or significances of a signal, but only provides an easily interpreted measure of the uncertainty of a single detector experiment.

A more useful statical tool is the covariance matrix, $E$, defined at each bin as
\begin{equation}
\begin{centering}
E^{i,j} = \frac{1}{M}\sum_{\text{All Univ.}~m}^{M} \left[ N^i_{\text{Nom.}} - N^i_{\text{Univ.~m}}\right] \times \left[ N^j_{\text{Nom.}} - N^j_{\text{Univ.~m}}\right].
\end{centering}
\label{eq:cov_mat}
\end{equation}

Covariance matrices that arise from uncertainty sources that are uncorrelated are separable, in the sense that for a complete analysis the final covariance matrix can be constructed as the sum of the matrices from each source.  In this analysis, a covariance matrix is calculated for the flux and cross section uncertainties for beam intrinsic events, and the matrix is estimated for the backgrounds from ``Dirt'' and cosmic induced events, as well as detector systematics.
\begin{equation}
\begin{centering}
\label{eq:tot_cov_mat}
E = E_{\text{Stat.}} + E_{\text{Flux}} + E_{\text{Cross Section}} + E_{\text{Dirt}} + E_{\text{Cosmic}} + E_{\text{Det. Syst.}}
\end{centering}
\end{equation}

The covariance matrix is more easily visualized in the form of some of it's transforms, the fractional covariance matrix
\begin{equation}
\begin{centering}
F^{i,j} \equiv \frac{E^{i,j}}{N^{i} N^{j}}
\end{centering}
\end{equation}
and the correlation matrix
\begin{equation}
\begin{centering}
C^{i,j} \equiv \frac{ E^{i,j} }{ \sqrt{E^{i,i}} \sqrt{E^{j,j}} }.
\end{centering}
\end{equation}

See Figures~\ref{fig:syst_flux_fracmatrix}, \ref{fig:syst_xsec_fracmatrix} for examples of the fractional covariance matrix, and Figures~\ref{fig:syst_flux_corrmatrix}, \ref{fig:syst_xsec_corrmatrix} for examples of the correlation matrix.  The fractional error matrix shows which analysis bins have the largest systematic uncertainty, though because it is relative it can be deceiving: bins with high systematic uncertainties might not be important bins in the analysis. 

The correlation matrix is an excellent visualization of the power of the covariance matrix technique.  It is limited to between -1 (full anticorrelation) and 1 (full correlation), and each entry at bin $(i,j)$ displays how correlated the $i^{th}$ bin is to the $j^{th}$ bin.  This is the vital information that allows correlated uncertainties in a multi detector experiment to cancel: a deviation at the far detector becomes significant (even if it is within the nominal uncertainty at that bin given by Eq. \ref{eq:bin_uncert}) if the deviation is not seen at a near detector {\bf and} the correlation between near and far is large.  The correlation matrices show the magnitude of exactly that correlation, while the covariance matrix (\ref{eq:cov_mat}) is the mathematical tool that carries correlation information to the $\chi^2$ calculation.


\section{Uncertainties from Neutrino Flux}

\label{section:flux_uncert}

As might be expected, the neutrino flux is highly correlated across the three detectors in the Booster Neutrino Beam.  However, the exact shape of the flux is not identical, especially at the near detector.  Figure~ \ref{sbn_flux} shows the flux at the three detectors, and the ratio of the near detector to both \uboone and \icarus, as well as \uboone to \icarus.

The covariance matrix for the uncertainties from the neutrino flux is built, as described above, using a multi universe approach.  As alluded to in Table~\ref{tab:mb_flux_uncert}, the uncertainties from the neutrino flux are well quantified by \MB.  However, their uncertainty calculations concerned a single detector, while the SBN Program is a multi detector experiment.  To properly quantify the correlated uncertainties between the three detectors, the flux at each detector has to be varied (using the multiple universe reweighting scheme above) consistently: in the $N^{th}$ Universe, the underlying physical parameters that have been changed are changed identically in all three detectors.  The event distributions can be calculated again in each universe, for all three detectors, and from them the covariance distribution is built for the flux uncertainties.

For the results shown here, the following uncertainties are considered in the computation of the flux covariance matrix:

\begin{itemize}
\item Primary production of $\pi^+$ , $\pi^-$ , $K^+$ , $K^−$ , and $K_L^0$ in p+Be collisions at 8 GeV
\item Secondary interactions of p, n, $\pi^{\pm}$ in the beryllium target and aluminum horn
\item Beam focusing with the magnetic horn
\end{itemize}

Primary hadron production uncertainties, whenever available, are taken directly from the
measured cross sections which are used to constrain the Monte Carlo. In the case
of charged pion production, the experimental uncertainties reported by the HARP experiment on
their measurements are directly used to set the allowed variation within the beamline simulation \cite{Catanesi:2007ab}.

For secondary interactions, the total cross sections are varied for hadrons on Beryllium and Aluminum.  Also, the inelastic and the quasielastic cross sections are varied.  Table~\ref{tab:flux_secondary_int_variations} summarizes allowed variations on hadron-Be and hadron-Al cross sections in the simulation. The total cross section, $\sigma_{\text{~TOT}}$, the inelastic cross section, $\sigma_{\text{~INE}}$ ; and the quasi-elastic cross sections, $\sigma_{\text{~QEL}}$ are varied separately for nucleons and pions interacting with Be and Al. When $\sigma_{\text{INE}}$ and $\sigma_{\text{QEL}}$ are varied, the cross section of the other is changed to hold the total cross section constant.

\begin{table}[h]
  \caption[BNB Secondary Interaction Variations]{Cross section variations for the study of systematic uncertainties from secondary interactions of hadrons in the target area.  The cross section is offset by the amount shown in the table.}
  \label{tab:flux_secondary_int_variations}
  \centering
  \begin{tabular}{l|ccccccc}
  \hline
  \hline
   &  \multicolumn{2}{c}{$\Delta \sigma_{\text{TOT}}$ (mb)} & \multicolumn{2}{c}{$\Delta \sigma_{\text{INE}}$ (mb)} & \multicolumn{2}{c}{$\Delta \sigma_{\text{QEL}}$ (mb)} \\
   &  Be & Al & Be & Al & Be & Al \\
  \hline
   $(p/n)$ - (Be/Al) & $\pm 15.0$ & $\pm 25.0$ & $\pm 5.0$ & $\pm 10.0$ & $\pm 20.0$ & $\pm 45.0$ \\
   $\pi^{\pm}$ - (Be/Al) & $\pm 11.9$ & $\pm 28.7$ & $\pm 10.0$ & $\pm 20.0$ & $\pm 11.2$ & $\pm 25.9$ \\
  \hline
  \end{tabular}
\end{table}

Beam focusing systematics include uncertainty on the magnitude of the horn current(174 $\pm$ 1 kA) as well as skin depth effects. the horn. The skin depth effect allows the magnetic field, flowing on the surface of the conductor, to penetrate into the interior of the horn conductor.This creates a magnetic field within the conductor that can lead to deflections of charged particles which traverse the conductor, especially at higher energy  when particles which do not penetrate deeply into the conductor. The effect can be approximated by modeling an exponentially decreasing field to a depth of about 1.4 mm. To asses the systematic the field is turned on and off, which leads to an energy dependent effect of 1 to 18\% for particles of < 1 GeV to 2 GeV, respectively \cite{AguilarArevalo:2008yp}.

This work does not include a systematic uncertainty on downstream interactions of hadrons with surrounding material, such as air, concrete, steel, etc.  These effects were studied by the \MB collaboration and found to contribute only a few percent to the \nue and \numu fluxes (1\% to \numu, 2\% to \nue).  Therefore, even a large uncertainty on downstream interaction would make a very small impact on the total uncertainty.

Figure~\ref{fig:sys_flux_uncert_fracUncert} shows the overall level on uncertainty on the event rates of electron neutrino backgrounds coming from flux uncertainties.  As described above, the events selected as \nue's are largely electron neutrinos with some background from neutral current interactions and charged current \numu interactions.  The uncertainties shown in Figure~\ref{fig:sys_flux_uncert_fracUncert} reflect the mixed composition of the background: in a ``Universe'' where the flux has varied, the \nue and \numu fluxes have been changed together and so all components of the background model are varied in a consistent way.

Naturally, the flux covariance matrix only applies to the part of the background that originates with the neutrino beam.  The cosmic background is independent of the flux, and though the ``dirt'' background does correlate with the beam, it is treated independently since the correlation is second order.

\begin{figure}[]
    \centering
    \includegraphics[width=0.75\textwidth]{systematics_figures/matrixFile_nue_ND_100m_uB_T600_onaxis_flux_6_ecalo2_nu_vePhot0.05_gap3_fracUncert}
    \caption[Fractional Flux Uncertainties]{The systematic uncertainties in the \nue appearance event rates for the SBN program, coming from uncertainties in the neutrino flux.  This includes flux-based uncertainties for both the \nue component, from the \nue flux, and the \numu misidentified component of the background.}
   \label{fig:sys_flux_uncert_fracUncert}
\end{figure}

\begin{figure}[]
    \centering
    \includegraphics[width=0.5\textwidth]{systematics_figures/matrixFile_nue_ND_100m_uB_T600_onaxis_flux_6_ecalo2_nu_vePhot0.05_gap3_fracMatHist}
    \caption[Flux Fractional Covariance Matrix]{The fractional covariance matrix for the flux uncertainties.  The uncertainties are highest in the tails of each detector's distributions.}
   \label{fig:syst_flux_fracmatrix}
\end{figure}
\begin{figure}[]
    \centering
    \includegraphics[width=0.5\textwidth]{systematics_figures/matrixFile_nue_ND_100m_uB_T600_onaxis_flux_6_ecalo2_nu_vePhot0.05_gap3_corrMatHist}
    \caption[Flux Correlation Matrix]{The correlation matrix for the flux uncertainties. The uncertainties are highly correlated across the three detectors, which is essential to achieving a strong cancellation between detectors. }
   \label{fig:syst_flux_corrmatrix}
\end{figure}



\section{Uncertainties from Neutrino Interactions}

After the flux uncertainty, the largest remaining uncertainty in a multidetector analysis is the uncertainty coming from neutrino interactions.  In particular, the flux and cross section uncertainties combine to form the overall normalization uncertainty on the event rates.

The use of the covariance method to compute a $\chi^2$ would be incorrect if the major normalization uncertainties were not all accounted for.  To address this, the systematic uncertainties from the neutrino interactions are also addressed with a covariance matrix.  As the simulation uses GENIE \cite{Andreopoulos:2009rq} to simulate neutrino interactions within argon, the same event generator was used to calculate the systematic uncertainties for cross sections.

At it's core, GENIE is a cross section calculator for neutrino interactions.  It models known interactions by computing cross section splines for a reaction between a specific flavor of neutrino and a nuclear target.  These splines are slow to create, and need to be comprehensive to have accurate results in the simulation.  At runtime, however, GENIE doesn't recompute cross sections for a particular neutrino onto a target if it is already computed, it just accesses the spline for the information.

All of the cross sections that GENIE computes are based on theory or fits to experimental data, and hence the parameters used (in the theory or fits) have some systematic uncertainty associated with them.  By varying these parameters according to their 1 $\sigma$ uncertainty, and recomputing the cross section, a weight can be applied to the event as described above in section Section ~\ref{sec:multi_weight}.

The GENIE framework provides a model for consistent variations of systematic uncertainties.  When, for example, a total cross section is constrained by data and a variation is requested on a subset of that total cross section, the other subsets are adjusted to compensate.  This gives a consistent ``Universe'' across all neutrino interactions when the underlying parameters are adjusted.

Table~\ref{tab:genie_xsec_params} shows the parameters that were varied in the GENIE cross section calculator for this analysis.  In each ``Universe,'' every parameter was varied within it's 1 $\sigma$ Gaussian distribution and the weights for each interaction were calculated, for a total of 250 universes.  Figure~\ref{fig:sys_xsec_uncert_fracUncert} shows the level of uncertainty in the detector's final \nue event rates arising from the cross section uncertainties.  This is, without a multi detector analysis, a very large source of uncertainty on the interaction rates.

{
\renewcommand{\arraystretch}{1.5}
\begin{table}[tb]
  \caption[Genie Cross Section Variations]{Genie Cross Section Variations and their nominal uncertainty, from \cite{Genie_manual}}
  \label{tab:genie_xsec_params}
  \centering

  \begin{tabular}{l|lc}
  \hline

  \hline
  \textbf{Parameter} & \textbf{Description} & \textbf{Nominal Variation} \\
  \hline
     $M_A^{CCQE}$ & Axial Mass for CC Quasi-Elastic & -15\% +25\%  \\
     $M_A^{CCRES}$ & Axial Mass for CC Resonance Production & $\pm$20\%  \\
     $M_A^{NCRES}$ & Axial Mass for NC Resonance Production & $\pm$20\%  \\
     $R_{bkg}^{\nu p, CC 1 \pi}$& Non-resonance Background in CC 1 $\pi$ production & $\pm$ 50\% \\
     $R_{bkg}^{\nu p, CC 2 \pi}$& Non-resonance Background in CC 2 $\pi$ production & $\pm$ 50\% \\
     $R_{bkg}^{\nu n, CC 1 \pi}$& Non-resonance Background in CC 1 $\pi$ production & $\pm$ 50\% \\
     $R_{bkg}^{\nu n, CC 2 \pi}$& Non-resonance Background in CC 2 $\pi$ production & $\pm$ 50\% \\
     $R_{bkg}^{\nu p, NC 1 \pi}$& Non-resonance Background in NC 1 $\pi$ production & $\pm$ 50\% \\
     $R_{bkg}^{\nu p, NC 2 \pi}$& Non-resonance Background in NC 2 $\pi$ production & $\pm$ 50\% \\
     $R_{bkg}^{\nu n, NC 1 \pi}$& Non-resonance Background in NC 1 $\pi$ production & $\pm$ 50\% \\
     $R_{bkg}^{\nu n, NC 2 \pi}$& Non-resonance Background in NC 2 $\pi$ production & $\pm$ 50\% \\
     % DIS Nucl. Model & & \\
  \hline

  \hline
  \end{tabular}
\end{table}
}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{systematics_figures/matrixFile_nue_ND_100m_uB_T600_onaxis_xsec_0_ecalo2_nu_vePhot0.05_gap3_fracUncert}
    \caption[\nue Cross Section Uncertainties]{Fractional uncertainties at each detector in the \nue analysis due to neutrino interaction uncertainties.}
   \label{fig:sys_xsec_uncert_fracUncert}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{systematics_figures/matrixFile_nue_ND_100m_uB_T600_onaxis_xsec_0_ecalo2_nu_vePhot0.05_gap3_fracMatHist}
    \caption[\nue Cross Section Fractional Covariance Matrix]{The fractional covariance matrix from the cross section uncertainties.}
   \label{fig:syst_xsec_fracmatrix}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{systematics_figures/matrixFile_nue_ND_100m_uB_T600_onaxis_xsec_0_ecalo2_nu_vePhot0.05_gap3_corrMatHist}
    \caption[\nue Cross Section Correlation Matrix]{The correlation matrix for the cross section uncertainties in the \nue analysis.  As seen by the very high correlation across the analysis bins, the cross section uncertainties are mostly a normalization uncertainty and not a shape uncertainty.}
   \label{fig:syst_xsec_corrmatrix}
\end{figure}


As seen in Figure~\ref{fig:syst_xsec_corrmatrix}, the cross section uncertainties across the detectors (and amongst the analysis bins within a detector) are highly correlated.  The even correlation indicates that the uncertainty is largely a normalization uncertainty, and not indicative of a different uncertainty in the energy dependence of the cross section, for example.  The only regions where the correlation is not as strong is the lowest energy bin to the higher energy bins in each detector.  Since the lowest energy bin has the highest rate of misidentified events, coming from Neutral Current pion producing interactions, it is sensible that this bin is less correlated to the rest.

Despite the very high correlation of cross section uncertainties, there are two caveats to this part of the study of systematic uncertainties in the SBN Program.  First, the uncertainties studied did not include final state interaction variations.  Because this is a Charged Current inclusive analysis, the final state interaction uncertainties should have minimal impact on the final result.  Any analysis that uses an exclusive channel, such as CC \nue 0 pion, would need a very careful study of the neutrino generator model and it's included uncertainties.

Second, the GENIE neutrino generator includes a package for systematic uncertainty study, however this list of channels studied is not expected to be 100\% comprehensive.  Instead, it serves to validate and quantify the level of correlation between the SBN detectors.

Despite these caveats, the conclusion of the cross section analysis is quite strong: whatever systematic uncertainties arise from neutrino interactions, they are very strongly correlated across the 3 detectors.  The quantification of that correlation is encoded in the covariance matrix, Figure~\ref{fig:syst_xsec_fracmatrix}.

\section{Residual Systematic Uncertainties}

After considering the flux and cross section uncertainties in detail, it is reasonable to ask what is the residual systematic uncertainty on a \nue appearance measurement in the SBN Program.

There are two types of uncertainties that are not studied in great detail yet, correlated and uncorrelated.  Some examples of correlated uncertainties that will be studied in the future, before the final analysis, are

\begin{itemize}
  \item {\bf Reconstruction Efficiencies} - the three detectors of the SBN Program will all use the same suite of reconstruction tools to build their event rates.  The efficiency will not be perfect, as no set of particle reconstruction software ever is, however the systematic biases introduced by the reconstruction will be correctable through Monte Carlo and well correlated between the detectors.  For the study shown here, reconstruction efficiencies are assumed to be the same across all three detectors.
  \item{\bf Cosmogenic Backgrounds} - the cosmogenic background, which occurs when a cosmic particle produces an interaction that is mistaken for an electron neutrino, will be mostly correlated between the three detectors.  There is some variance in the building geometries, such as overburdens and cosmic tagging systems (muon detectors external to the cryostat), however the basic cosmic flux at all three detectors will be correlated.  Further, the cosmogenic background can be measured with nearly arbitrary precision with off-beam spills.  That is, since the neutrino beams are pulsed there are clear samples of data with {\bf no} neutrinos, which can be used to measure the amount of cosmogenic misidentification as electron neutrinos.  Under this assumption, the covariance matrix for the cosmic sample is the statistical uncertainty of the cosmic misidentification in the accepted event samples.

\end{itemize}

On the other hand, residual uncorrelated uncertainties include

\begin{itemize}
  \item {\bf Detector Effects} - The three detectors of the SBN Program, while all LArTPCs, are not identical detectors in the same way that Daya Bay is, for example \cite{An:2015qga}.  As described in Section~\ref{sec:sbn_detectors}, the three detectors have some differences.  \uboone is a single drift detector, while \icarus and \sbnd are dual drift TPCs with a cathode in the middle.  Further, the fiducial volumes of the detectors are different, and the ability to contain neutral particles and electromagnetic particles is different due to the different shape of the detectors.
  \item{\bf ``Dirt'' Backgrounds} - the backgrounds produced by the beam but externally to the detector will, to first order, be uncorrelated between detectors.  The overall rate will fluctuate up or down with the neutrino flux, however the complexity of the surrounding material of the detectors makes the evaluation difficult.  Therefore, to be conservative, a 15\% uncertainty is applied to the ``Dirt'' backgrounds at each detector.  This is assumed to be fully correlated within each detector's analysis bins, but uncorrelated across detectors.
\end{itemize}

Before a final analysis is released, these systematics uncertainties must be carefully addressed.

\section{Sensitivity to Anomalous \nue Appearance at the SBN Program}

To evaluate the expect sensitivity of the SBN Program, the above covariance matrices are used as shown in Equation~\ref{eq:tot_cov_mat}.  The $\chi^2$ measure of sensitivity is computed as in Equation~\ref{eq:chi_sq}.  The final sensitivity to \nue is shown in Figure~\ref{fig:sbn_final_sensitivity}.  As an alternative view to this sensitivity, the quoted sensitivity in Figure~\ref{fig:sbn_alt_sensitivity} shows the $\sqrt{\chi^2}$ of calculated along the left edge of the LSND 90\% confidence region.


\begin{figure}[tb]
  \centering
  \includegraphics[width=0.75\textwidth]{systematics_figures/{ND_100m_uB_T600_onaxis_nue_appearance_ecalo2_nu_vePhot0.05_gap3_lessCosmics_xsec_0_flux_6_dirt_cos_sensPlot.pdf}}
  \caption[SBN Sensitivity]{The SBN Program's quoted sensitivity, under all the assumptions shown above. At the best fit points from \cite{kopp_best_fit} and \cite{giunti_best_fit}, the significance is well above 5 $\sigma$.}
  \label{fig:sbn_final_sensitivity}
\end{figure}



\begin{figure}[tb]
  \centering
  \includegraphics[width=\textwidth]{systematics_figures/{nominalSBNSens.pdf}}
  \caption[SBN Sensitivity Along LSND Edge]{The SBN Sensitivity along the lower edge of the LSND 90\% confidence allowed region.  Because of the low $\text{sin}^22\theta$ values along the LSND regions left edge, this is a region with a very small and difficult to measure signal.  Therefore, it is a good parameter space with which to measure the SBN Sensitivity.}
  \label{fig:sbn_alt_sensitivity}
\end{figure}